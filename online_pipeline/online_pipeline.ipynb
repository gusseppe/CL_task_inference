{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "253e5710-baf6-42cd-9670-17d01642f40d",
   "metadata": {},
   "source": [
    "# Online Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a20811f-7e6f-47b6-a454-2dabe7b8f264",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import clip\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from PIL import Image\n",
    "from rich import print\n",
    "# to_pil = transforms.ToPILImage()\n",
    "\n",
    "\n",
    "def find_avg_centroid(x):\n",
    "    return np.mean(x, axis=0)\n",
    "\n",
    "# def find_avg_centroid(x):\n",
    "#     length, dim = x.shape\n",
    "#     return np.array([np.sum(x[:, i])/length for i in range(dim)])\n",
    "\n",
    "def find_nearest_centroids(x, y):\n",
    "    if not isinstance(x, (np.ndarray, np.generic)):\n",
    "        x = x.detach().cpu().numpy()\n",
    "        \n",
    "    clf = NearestCentroid(metric='manhattan')\n",
    "    clf = clf.fit(x, y)\n",
    "    centroids = clf.centroids_\n",
    "    return centroids\n",
    "\n",
    "def find_knn(x, centroids, n_neighbors=10):\n",
    "    if not isinstance(x, (np.ndarray, np.generic)):\n",
    "        x = x.detach().cpu().numpy()\n",
    "\n",
    "    knn_search = NearestNeighbors(n_neighbors=n_neighbors,\n",
    "                            # metric='cosine', # because CLIP model\n",
    "                            metric='manhattan', # because CLIP model\n",
    "                            algorithm='auto', #'ball_tree'\n",
    "                            n_jobs=-1)  \n",
    "    knn_search.fit(x)\n",
    "\n",
    "    indexes = knn_search.kneighbors(centroids, return_distance=False)\n",
    "    return x[indexes][0]\n",
    "\n",
    "        \n",
    "def get_clusters(x):\n",
    "    # X = mde_embedding\n",
    "    # x = x.detach().cpu().numpy()\n",
    "    # db = DBSCAN(eps=0.8, min_samples=10, n_jobs=-1, metric='manhattan').fit(X)\n",
    "    # db = OPTICS(min_samples=2).fit(x)\n",
    "    db = DBSCAN(eps=0.3, min_samples=10, leaf_size=30, \n",
    "                n_jobs=-1, metric='cosine').fit(x)\n",
    "\n",
    "    # core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "    # core_samples_mask[db.core_sample_indices_] = True\n",
    "    labels = db.labels_\n",
    "    # Number of clusters in labels, ignoring noise if present.\n",
    "    n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    n_noise_ = list(labels).count(-1)\n",
    "\n",
    "    print(\"Estimated number of clusters: %d\" % n_clusters_)\n",
    "    print(\"Estimated number of noise points: %d\" % n_noise_)\n",
    "    if n_clusters_ == 0:\n",
    "        return x, labels, n_clusters_\n",
    "    # Remove outliers to avoid affecting the centroids\n",
    "    x = x[np.where(labels != -1)]\n",
    "    labels = labels[np.where(labels != -1)]\n",
    "    \n",
    "    return x, labels, n_clusters_\n",
    "\n",
    "\n",
    "def get_nearest_embedding_centroids(x, n_neighbors=10):\n",
    "    # print(task.task.title())\n",
    "    # print(f\"CLIP Embedding shape: {task.embeddings.shape}\")\n",
    "    \n",
    "    #1. Get the CLIP embeddings\n",
    "    if not isinstance(x, (np.ndarray, np.generic)):\n",
    "        x = x.detach().cpu().numpy()\n",
    "    \n",
    "    #3. Cluster the embeddings\n",
    "    x, labels, n_clusters = get_clusters(x)\n",
    "\n",
    "    #4. Find centroids of embeddings\n",
    "    if n_clusters < 2:\n",
    "        centroids = find_avg_centroid(x)\n",
    "        centroids = centroids.reshape(1, -1)\n",
    "    else:\n",
    "        centroids = find_nearest_centroids(x, labels)\n",
    "\n",
    "    # If some infinite/nan values appear\n",
    "    centroids = np.nan_to_num(centroids)\n",
    "    #5. Find knn of centroids        \n",
    "    x_nearest_centroids = find_knn(x, centroids, n_neighbors)\n",
    "    # x_nearest_centroids2 = np.vstack([find_knn(x, [centroid], n_neighbors) for centroid in centroids])\n",
    "    # return centroids\n",
    "    x_chosen = np.vstack([centroids, x_nearest_centroids])\n",
    "    # x_chosen = np.vstack([centroids, x_nearest_centroids, x_nearest_centroids2])\n",
    "    print(f\"# nearest centroids ({round((x_chosen.shape[0]/x.shape[0])*100, 2)}%):\", x_chosen.shape)\n",
    "    print()\n",
    "\n",
    "    return x_chosen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5a0fe93-5b7e-4cc5-8ae7-a61abf0ee274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Device:  cpu\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Device:  cpu\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device: \", device)\n",
    "embeder, preprocess = clip.load(\"ViT-B/32\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98da3422-f09e-4c73-9fde-67e4b00c600b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from functools import lru_cache\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def get_embeddings(dataset):\n",
    "    \n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_tasks = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels, tasks in tqdm(DataLoader(dataset, batch_size=100, num_workers=8)):\n",
    "            features = embeder.encode_image(images.to(device))\n",
    "            # features = embeder_resnet(images.to(device)).squeeze()\n",
    "\n",
    "            all_features.append(features)\n",
    "            all_labels.append(labels)\n",
    "            all_tasks.append(tasks)\n",
    "\n",
    "    return (torch.cat(all_features).cpu().numpy(), \n",
    "            torch.cat(all_labels).cpu().numpy(), torch.cat(all_tasks).cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14afcde3-770b-4cd8-8246-4ac63a23e9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./CLAD/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94c87fbd-08b1-45bd-af75-ab282b73c42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] No Detectron installation found, continuing without.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m6\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5157</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1154</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6742</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2560</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4517</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2119</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[1;36m5157\u001b[0m, \u001b[1;36m1154\u001b[0m, \u001b[1;36m6742\u001b[0m, \u001b[1;36m2560\u001b[0m, \u001b[1;36m4517\u001b[0m, \u001b[1;36m2119\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import clad\n",
    "import torchvision\n",
    "\n",
    "root = \"./data\"\n",
    "original_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.3252, 0.3283, 0.3407), (0.0265, 0.0241, 0.0252))\n",
    "\n",
    "])\n",
    "\n",
    "# all_train_sets = clad.get_cladc_train(root, transform=lambda x: x)\n",
    "all_train_sets = clad.get_cladc_train(root, transform=original_transform)\n",
    "# val_sets = clad.get_cladc_val(root, transform=torchvision.transforms.ToTensor())\n",
    "print(len(all_train_sets))\n",
    "print([len(ts) for ts in all_train_sets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cee7fb2-0852-4446-81d5-1d707cd4fd18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m6\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5157</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1154</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6742</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2560</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4517</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2119</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[1;36m5157\u001b[0m, \u001b[1;36m1154\u001b[0m, \u001b[1;36m6742\u001b[0m, \u001b[1;36m2560\u001b[0m, \u001b[1;36m4517\u001b[0m, \u001b[1;36m2119\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# method_transform = torchvision.transforms.Compose([\n",
    "#     torchvision.transforms.ToTensor(),\n",
    "#     torchvision.transforms.ToPILImage()\n",
    "# ])\n",
    "method_transform = torchvision.transforms.Compose([\n",
    "    preprocess\n",
    "])\n",
    "all_train_sets_method = clad.get_cladc_train(root, transform=method_transform)\n",
    "print(len(all_train_sets_method))\n",
    "print([len(ts) for ts in all_train_sets_method])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75c9161e-d405-4b9b-9628-0ad7cf37598c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Original data\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Original data\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Training lenghts: \n",
       "<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4125</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">923</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5393</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3613</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1695</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Training lenghts: \n",
       "\u001b[1m[\u001b[0m\u001b[1;36m4125\u001b[0m, \u001b[1;36m923\u001b[0m, \u001b[1;36m5393\u001b[0m, \u001b[1;36m2048\u001b[0m, \u001b[1;36m3613\u001b[0m, \u001b[1;36m1695\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Testing lenghts: \n",
       "<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1032</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">231</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1349</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">904</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">424</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Testing lenghts: \n",
       "\u001b[1m[\u001b[0m\u001b[1;36m1032\u001b[0m, \u001b[1;36m231\u001b[0m, \u001b[1;36m1349\u001b[0m, \u001b[1;36m512\u001b[0m, \u001b[1;36m904\u001b[0m, \u001b[1;36m424\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Method data\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Method data\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Training lenghts: \n",
       "<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4125</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">923</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5393</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3613</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1695</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Training lenghts: \n",
       "\u001b[1m[\u001b[0m\u001b[1;36m4125\u001b[0m, \u001b[1;36m923\u001b[0m, \u001b[1;36m5393\u001b[0m, \u001b[1;36m2048\u001b[0m, \u001b[1;36m3613\u001b[0m, \u001b[1;36m1695\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Testing lenghts: \n",
       "<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1032</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">231</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1349</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">904</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">424</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Testing lenghts: \n",
       "\u001b[1m[\u001b[0m\u001b[1;36m1032\u001b[0m, \u001b[1;36m231\u001b[0m, \u001b[1;36m1349\u001b[0m, \u001b[1;36m512\u001b[0m, \u001b[1;36m904\u001b[0m, \u001b[1;36m424\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "# Define the split sizes for each dataset\n",
    "train_size = 0.8\n",
    "# test_size = 0.2\n",
    "\n",
    "# Split each dataset in the train_sets list into training and testing sets\n",
    "train_sets = []\n",
    "test_sets = []\n",
    "for dataset in all_train_sets:\n",
    "    dataset_size = len(dataset)\n",
    "    train_dataset_size = int(train_size * dataset_size)\n",
    "    test_dataset_size = dataset_size - train_dataset_size\n",
    "    train_dataset, test_dataset = random_split(dataset, [train_dataset_size, test_dataset_size], \n",
    "                                               generator=torch.Generator().manual_seed(42))\n",
    "    train_sets.append(train_dataset)\n",
    "    test_sets.append(test_dataset)\n",
    "\n",
    "print(\"Original data\")\n",
    "print('Training lenghts: ', [len(ts) for ts in train_sets])\n",
    "print('Testing lenghts: ', [len(ts) for ts in test_sets])\n",
    "\n",
    "train_sets_method = []\n",
    "test_sets_method = []\n",
    "for dataset in all_train_sets_method:\n",
    "    dataset_size = len(dataset)\n",
    "    train_dataset_size = int(train_size * dataset_size)\n",
    "    test_dataset_size = dataset_size - train_dataset_size\n",
    "    train_dataset, test_dataset = random_split(dataset, [train_dataset_size, test_dataset_size], \n",
    "                                               generator=torch.Generator().manual_seed(42))\n",
    "    train_sets_method.append(train_dataset)\n",
    "    test_sets_method.append(test_dataset)\n",
    "\n",
    "print(\"Method data\")\n",
    "print('Training lenghts: ', [len(ts) for ts in train_sets_method])\n",
    "print('Testing lenghts: ', [len(ts) for ts in test_sets_method])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd44e5d6-9566-4b52-9440-347d2bc8e851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 511 ms, sys: 147 ms, total: 659 ms\n",
      "Wall time: 712 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from torch.utils.data.dataset import TensorDataset\n",
    "from avalanche.benchmarks.utils import AvalancheDataset\n",
    "from avalanche.benchmarks.utils import make_classification_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from avalanche.benchmarks.generators import filelist_benchmark, dataset_benchmark\n",
    "\n",
    "\n",
    "\n",
    "# Original benchmark with tasks\n",
    "training_datasets = list()\n",
    "testing_datasets = list()\n",
    "\n",
    "for task, (train_s, test_s) in enumerate(zip(train_sets, test_sets), start=0):\n",
    "    training_datasets.append(make_classification_dataset(train_s, task_labels=np.repeat(task, len(train_s))))\n",
    "    testing_datasets.append(make_classification_dataset(test_s, task_labels=np.repeat(task, len(test_s))))\n",
    "\n",
    "benchmark= dataset_benchmark(\n",
    "    training_datasets,\n",
    "    testing_datasets\n",
    ")\n",
    "\n",
    "# Original benchmark without tasks\n",
    "training_datasets = list()\n",
    "testing_datasets = list()\n",
    "for task, (train_s, test_s) in enumerate(zip(train_sets, test_sets), start=0):\n",
    "    training_datasets.append(make_classification_dataset(train_s, task_labels=np.repeat(0, len(train_s))))\n",
    "    testing_datasets.append(make_classification_dataset(test_s, task_labels=np.repeat(0, len(test_s))))\n",
    "\n",
    "benchmark_no_task= dataset_benchmark(\n",
    "    training_datasets,\n",
    "    testing_datasets\n",
    ")\n",
    "\n",
    "# Method benchmark\n",
    "training_datasets = list()\n",
    "testing_datasets = list()\n",
    "for task, (train_s, test_s) in enumerate(zip(train_sets_method, test_sets_method), start=0):\n",
    "    training_datasets.append(make_classification_dataset(train_s, task_labels=np.repeat(task, len(train_s))))\n",
    "    testing_datasets.append(make_classification_dataset(test_s, task_labels=np.repeat(task, len(test_s))))\n",
    "\n",
    "benchmark_method= dataset_benchmark(\n",
    "    training_datasets,\n",
    "    testing_datasets\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40a8f9d-0a39-4ef0-ad6f-a8c92aae9f63",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff6433aa-6141-458c-ad06-26b6244a9481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Getting embeddings\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Getting embeddings\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:33<00:00,  1.25it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">x_train shape: \n",
       "<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4125</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "x_train shape: \n",
       "\u001b[1m(\u001b[0m\u001b[1;36m4125\u001b[0m, \u001b[1;36m512\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:09<00:00,  1.13it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">x_test shape: \n",
       "<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1032</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "x_test shape: \n",
       "\u001b[1m(\u001b[0m\u001b[1;36m1032\u001b[0m, \u001b[1;36m512\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Getting embeddings\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Getting embeddings\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:09<00:00,  1.10it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">x_train shape: \n",
       "<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">923</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "x_train shape: \n",
       "\u001b[1m(\u001b[0m\u001b[1;36m923\u001b[0m, \u001b[1;36m512\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:04<00:00,  1.50s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">x_test shape: \n",
       "<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">231</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "x_test shape: \n",
       "\u001b[1m(\u001b[0m\u001b[1;36m231\u001b[0m, \u001b[1;36m512\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Getting embeddings\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Getting embeddings\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:37<00:00,  1.45it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">x_train shape: \n",
       "<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5393</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "x_train shape: \n",
       "\u001b[1m(\u001b[0m\u001b[1;36m5393\u001b[0m, \u001b[1;36m512\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:11<00:00,  1.27it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">x_test shape: \n",
       "<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1349</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "x_test shape: \n",
       "\u001b[1m(\u001b[0m\u001b[1;36m1349\u001b[0m, \u001b[1;36m512\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Getting embeddings\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Getting embeddings\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:15<00:00,  1.33it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">x_train shape: \n",
       "<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "x_train shape: \n",
       "\u001b[1m(\u001b[0m\u001b[1;36m2048\u001b[0m, \u001b[1;36m512\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:06<00:00,  1.01s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">x_test shape: \n",
       "<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "x_test shape: \n",
       "\u001b[1m(\u001b[0m\u001b[1;36m512\u001b[0m, \u001b[1;36m512\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Getting embeddings\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Getting embeddings\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37/37 [00:25<00:00,  1.45it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">x_train shape: \n",
       "<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3613</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "x_train shape: \n",
       "\u001b[1m(\u001b[0m\u001b[1;36m3613\u001b[0m, \u001b[1;36m512\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">x_test shape: \n",
       "<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">904</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "x_test shape: \n",
       "\u001b[1m(\u001b[0m\u001b[1;36m904\u001b[0m, \u001b[1;36m512\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Getting embeddings\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Getting embeddings\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:14<00:00,  1.15it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">x_train shape: \n",
       "<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1695</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "x_train shape: \n",
       "\u001b[1m(\u001b[0m\u001b[1;36m1695\u001b[0m, \u001b[1;36m512\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:05<00:00,  1.19s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">x_test shape: \n",
       "<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">424</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "x_test shape: \n",
       "\u001b[1m(\u001b[0m\u001b[1;36m424\u001b[0m, \u001b[1;36m512\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_stream = benchmark_method.train_stream\n",
    "test_stream = benchmark_method.test_stream\n",
    "\n",
    "all_x_train_emb = list()\n",
    "all_y_train = list()\n",
    "all_t_train = list()\n",
    "\n",
    "all_x_test_emb = list()\n",
    "all_y_test = list()\n",
    "all_t_test = list()\n",
    "\n",
    "\n",
    "for task, experience in enumerate(train_stream):\n",
    "    print(\"Getting embeddings\")\n",
    "    x_train_emb, y_train, t_train = get_embeddings(train_stream[task].dataset)\n",
    "\n",
    "    print(\"x_train shape: \", x_train_emb.shape)\n",
    "    all_x_train_emb.append(x_train_emb)\n",
    "    all_y_train.append(y_train)\n",
    "    all_t_train.append(t_train)\n",
    "\n",
    "    x_test_emb, y_test, t_test = get_embeddings(test_stream[task].dataset)\n",
    "    print(\"x_test shape: \", x_test_emb.shape)\n",
    "    all_x_test_emb.append(x_test_emb)\n",
    "    all_y_test.append(y_test)\n",
    "    all_t_test.append(t_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cff3824-aa5f-4a21-abd9-6ad3136f0eb4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e89131-b881-4495-8e55-dcf30ce37bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Memory:\n",
    "    task: int\n",
    "    shape: List = None\n",
    "    centroids: InitVar[List] = None\n",
    "    def __post_init__(self, points):\n",
    "        self.centroids = points\n",
    "        self.shape = self.centroids.shape\n",
    "\n",
    "def online_pipeline(memory, task, x_new):\n",
    "    decisions = list()\n",
    "\n",
    "    # If Empty memory -> save points and use model\n",
    "    if not memory:  \n",
    "        # print(\"Empty memory\")\n",
    "        return ['save_centroids', 'use_head']\n",
    "    \n",
    "    drift_history = []\n",
    "    for index, x_ref in enumerate(memory[::-1], start=1): # loop in reversed order\n",
    "        # print(f\"Calculating drift between Task(current={task}, memory={x_ref.task})\")\n",
    "        drift = calculate_drift(x_ref.centroids, x_new)\n",
    "        is_drift = drift['data']['is_drift']\n",
    "\n",
    "        \n",
    "        # Case when the next task is the same as before (two consecutive tasks are the same)\n",
    "        if (index == 1) and (not is_drift):  \n",
    "            return ['use_head']  \n",
    "        \n",
    "        drift_history.append(is_drift)\n",
    "\n",
    "    # all(drift(task, each element in memory)) = True, that is, not known task\n",
    "    if all(drift_history):  \n",
    "        return ['save_centroids', 'train_task_classifier', 'add_head', 'use_head']\n",
    "    else: # any(drift(task, each element in memory)) = False, that is, known task\n",
    "        return ['classify_task', 'use_head']\n",
    "\n",
    "for task in enumerate(sequence):\n",
    "    x_new = get_nearest_embedding_centroids(train_dict[task], n_neighbors=10)\n",
    "    decisions = online_pipeline(memory, task, x_new)\n",
    "    task_id = task\n",
    "    for decision in decisions:\n",
    "        if decision == 'save_centroids':  # save new points in memory\n",
    "            memory.append(Memory(task=task, centroids=x_new))\n",
    "        elif decision == 'train_task_classifier':  # train the task classifier because there is drift\n",
    "            x_train = [m.centroids for m in memory]\n",
    "            y_train = [np.repeat(m.task, m.shape[0]) for m in memory]\n",
    "            x_train = np.vstack(x_train)\n",
    "            y_train = np.hstack(y_train)\n",
    "            classifier = get_classifier(x_train, y_train)\n",
    "            task_id = memory[-1].task # last task_id\n",
    "        elif decision == 'classify_task':  # classify the new points using the task classifier\n",
    "            task_id = classifier.predict(x_new)\n",
    "            task_id = stats.mode(task_id, keepdims=True) # takes the mode of the predictions\n",
    "            task_id = int(task_id[0])\n",
    "        elif decision == 'add_head':  # add new head to current multi-head model\n",
    "            models = add_head_model(models, x_new, y_new, task_id) # Add head based on task_id\n",
    "        elif decision == 'use_head':  # use current head based on task_id\n",
    "            use_model_head(models, x_val, y_val, task_id)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch] *",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
